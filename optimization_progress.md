# 성능 최적화 진행 상황

## 목표 성능
- 프롬프트 평가: **20-50 ms/token** (목표)
- 토큰 생성: **50-200 ms/token** (목표)

## 현재 성능 (최적화 전)
- 프롬프트 평가: **168.82 ms/token** (5.93 tokens/sec)
- 토큰 생성: 약 **500 ms/token** (2 tokens/sec)
- **목표 대비 3.4-8.4배 느림**

## 적용된 최적화

### 1. 배치 크기 최적화 ✅
- **변경 사항:**
  - `n_batch`: 64 → **128**
  - `n_ubatch`: 8 → **16**
- **기대 효과:** GPU 활용률 향상, 데이터 전송 오버헤드 감소
- **상태:** 완료

### 2. 디버그 로그 제거 ✅
- **변경 사항:**
  - `sync_with_other_backends`: 과도한 WARN 로그 제거
  - `ggml_backend_opencl_graph_compute`: SET_ROWS Q4_0 관련 상세 로그 제거
  - `ggml_backend_opencl_buffer_get_tensor`: Q4_0/MXFP4/Q8_0 블록 내부 상세 로그 제거
- **기대 효과:** 로그 오버헤드 감소, I/O 병목 완화
- **상태:** 완료

### 3. 동적 청크 크기 최적화 ✅
- **변경 사항:**
  - 청크 크기가 `n_batch`(128)와 자동으로 일치하도록 설정
  - 프롬프트 길이에 따라 동적 조정
- **기대 효과:** GPU 메모리 효율성 극대화
- **상태:** 완료

### 4. KV 캐시 GPU 할당 ✅ (이전 최적화)
- **변경 사항:**
  - KV 캐시를 GPU(OpenCL)에 할당
  - SET_ROWS Q4_0 지원 추가
- **기대 효과:** CPU-GPU 데이터 전송 오버헤드 제거
- **상태:** 완료

## 추가 최적화 방안

### 5. GPU 레이어 수 최적화 (대기 중)
- **현재 설정:** `n_gpu_layers = 31` (거의 모든 레이어)
- **최적화 방안:**
  - VRAM 사용량 모니터링
  - 레이어 수를 32-33으로 증가 시도 (VRAM 여유 시)
  - 또는 레이어 수를 29-30으로 감소하여 배치 크기 증가 여유 확보

### 6. 스레드 수 최적화 (대기 중)
- **현재 설정:** `n_threads = 8`, `n_threads_batch = 8`
- **최적화 방안:**
  - CPU 코어 수에 맞춰 조정
  - 배치 처리 스레드 수 독립 조정

### 7. OpenCL 커널 최적화 (대기 중)
- **최적화 방안:**
  - SET_ROWS Q4_0 커널 워크그룹 크기 조정
  - 로컬 메모리 사용 최적화
  - 커널 파이프라인 최적화

### 8. 메모리 접근 패턴 최적화 (대기 중)
- **최적화 방안:**
  - 텐서 메모리 정렬 최적화
  - 캐시 친화적 데이터 배치
  - 불필요한 메모리 복사 제거

## 성능 측정 계획

1. **1차 측정:** 배치 크기 128, 로그 제거 후 성능 측정
2. **2차 측정:** GPU 레이어 수 조정 후 성능 측정
3. **3차 측정:** 스레드 수 조정 후 성능 측정
4. **4차 측정:** OpenCL 커널 최적화 후 성능 측정

## 목표 달성 기준

- 프롬프트 평가: **≤ 50 ms/token** (목표 상한)
- 토큰 생성: **≤ 200 ms/token** (목표 상한)
- 안정성: 크래시 없이 정상 동작

## 다음 단계

1. 현재 최적화 적용 후 성능 측정
2. 성능 분석 및 병목 지점 파악
3. 추가 최적화 적용
4. 목표 성능 달성까지 반복

