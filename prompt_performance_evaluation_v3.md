# 프롬프트 평가 성능 분석 v3

## 측정 일시
- 2024-11-17 00:12:04 ~ 00:12:34

## 현재 성능 측정 결과

### 전체 프롬프트 평가
- **총 토큰 수:** 327 토큰
- **총 소요 시간:** 30,419 ms (약 30.4초)
- **평균 토큰당 시간:** **93.02 ms/token**
- **처리량:** **10.75 tokens/sec**

### 청크별 성능 분석

| 청크 | 토큰 범위 | 소요 시간 | 평균 ms/token | 비고 |
|------|----------|----------|---------------|------|
| 청크 1 | 0-128 | 11,232 ms | 87.75 | 첫 청크 (초기화 오버헤드) |
| 청크 2 | 128-256 | 11,549 ms | 90.23 | 중간 청크 |
| 청크 3 | 256-327 | 7,637 ms | 107.56 | 마지막 청크 (작은 크기) |

**관찰:**
- 마지막 청크(71 토큰)가 상대적으로 느림 (107.56 ms/token)
- 작은 청크 크기로 인한 GPU 활용률 저하 가능성

## 성능 개선 추이

| 버전 | ms/token | tokens/sec | 개선율 |
|------|----------|------------|--------|
| 초기 (KV 캐시 CPU) | 168.82 | 5.93 | 기준 |
| v2 (KV 캐시 GPU) | 168.82 | 5.93 | 0% |
| **v3 (배치 128, 로그 제거)** | **93.02** | **10.75** | **+45%** |

## 목표 성능 대비

| 항목 | 목표 | 현재 | 달성률 | 부족분 |
|------|------|------|--------|--------|
| 프롬프트 평가 | 20-50 ms/token | 93.02 ms/token | 21.5-46.5% | 1.86-4.65배 느림 |
| 처리량 | 20-50 tokens/sec | 10.75 tokens/sec | 21.5-53.8% | 1.86-4.65배 느림 |

## 현재 시스템 설정

```kotlin
nCtx = 512
nBatch = 128        // 최적화: 64 → 128
nUbatch = 16        // 최적화: 8 → 16
nGpuLayers = 31     // 거의 모든 레이어
nThreads = 8
백엔드: OpenCL
KV 캐시: GPU (OpenCL)
청크 크기: 128 (n_batch와 일치)
```

## 적용된 최적화

1. ✅ **배치 크기 증가** (64 → 128)
   - GPU 활용률 향상
   - 데이터 전송 오버헤드 감소

2. ✅ **디버그 로그 제거**
   - `sync_with_other_backends` 로그 제거
   - `ggml_backend_opencl_graph_compute` 로그 제거
   - `ggml_backend_opencl_buffer_get_tensor` 로그 제거

3. ✅ **동적 청크 크기 최적화**
   - 청크 크기 = n_batch (128)
   - GPU 메모리 효율성 극대화

4. ✅ **KV 캐시 GPU 할당** (이전)
   - SET_ROWS Q4_0 지원 추가
   - CPU-GPU 데이터 전송 오버헤드 제거

## 성능 병목 지점 분석

### 1. 청크 처리 시간 분석
- **청크당 평균 시간:** 약 10-11초
- **토큰당 평균 시간:** 87-108 ms/token
- **관찰:** 마지막 작은 청크(71 토큰)가 상대적으로 느림

### 2. 잠재적 병목
- **OpenCL 커널 실행 시간:** 각 레이어의 GPU 연산 시간
- **메모리 전송:** KV 캐시 접근 패턴
- **동기화 오버헤드:** OpenCL 커맨드 큐 동기화
- **작은 청크 처리:** 마지막 청크(71 토큰)의 GPU 활용률 저하

## 다음 최적화 방안

### 우선순위 1: 작은 청크 병합
- **문제:** 마지막 청크(71 토큰)가 상대적으로 느림
- **해결:** 마지막 청크를 이전 청크와 병합하여 처리
- **기대 효과:** 5-10% 개선

### 우선순위 2: OpenCL 커널 최적화
- **작업:** SET_ROWS Q4_0 커널 워크그룹 크기 조정
- **기대 효과:** 10-20% 개선

### 우선순위 3: GPU 레이어 수 미세 조정
- **현재:** 31 레이어 (거의 모든 레이어)
- **시도:** 32-33 레이어 (VRAM 여유 시)
- **기대 효과:** 5-10% 개선

### 우선순위 4: 스레드 수 최적화
- **현재:** 8 스레드
- **시도:** CPU 코어 수에 맞춰 조정
- **기대 효과:** 5-10% 개선

## 목표 달성 계획

현재 성능: **93.02 ms/token**
목표 성능: **20-50 ms/token**

**필요한 개선:** 약 **1.86-4.65배** 추가 개선

**단계별 목표:**
1. 1차 목표: 70 ms/token (약 25% 개선)
2. 2차 목표: 50 ms/token (약 46% 개선) - 목표 상한
3. 최종 목표: 20-30 ms/token (약 68-78% 개선) - 목표 범위

## 결론

현재까지 **45% 성능 개선**을 달성했습니다. 하지만 목표 성능(20-50 ms/token)에는 아직 **1.86-4.65배** 추가 개선이 필요합니다.

다음 최적화 단계로 **작은 청크 병합**과 **OpenCL 커널 최적화**를 진행하여 목표 성능에 근접하도록 하겠습니다.

