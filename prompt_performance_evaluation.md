# 프롬프트 평가 성능 분석

## 측정 일시
- 2024년 11월 16일
- 측정 환경: Android 기기 (Adreno GPU)

## 현재 시스템 설정

### 모델 설정
- **모델**: llama31-banyaa-q4_0.gguf
- **양자화**: Q4_0
- **컨텍스트 크기 (nCtx)**: 512
- **배치 크기 (nBatch)**: 64
- **마이크로 배치 크기 (nUbatch)**: 8
- **GPU 레이어 수 (nGpuLayers)**: 31
- **CPU 스레드 수 (nThreads)**: 8

### 백엔드 설정
- **백엔드**: OpenCL
- **KV 캐시 위치**: CPU (SET_ROWS 호환성을 위해 강제 할당)
- **동적 청크 크기**: 64 토큰 (n_batch와 일치)

## 측정 결과

### 프롬프트 평가 성능

**측정 데이터:**
- **프롬프트 토큰 수**: 327 토큰
- **총 소요 시간**: 85,394 ms (약 85.4초)
- **평균 토큰당 시간**: 261.14 ms/token
- **처리량**: 약 3.83 tokens/sec

### 성능 지표

| 항목 | 값 | 비고 |
|------|-----|------|
| 총 평가 시간 | 85.4초 | 327 토큰 처리 |
| 평균 토큰당 시간 | 261.14 ms/token | 목표 대비 매우 느림 |
| 처리량 | 3.83 tokens/sec | 목표 대비 매우 느림 |
| 동적 청크 크기 | 64 토큰 | n_batch와 일치 |

## 성능 비교

### 목표 성능 (일반적인 LLM 추론)
- **프롬프트 평가**: 20-50 ms/token
- **처리량**: 20-50 tokens/sec

### 현재 성능
- **프롬프트 평가**: 261.14 ms/token
- **처리량**: 3.83 tokens/sec

### 성능 차이
- **목표 대비**: 약 **5-13배 느림**
- **개선 필요**: 약 **85-90% 성능 향상** 필요

## 주요 성능 병목 지점

### 1. KV 캐시가 CPU에 할당됨 (가장 큰 병목)
- **현재 상태**: KV 캐시가 CPU 메모리에 할당됨
- **영향**: GPU 연산 시 KV 캐시 데이터를 CPU ↔ GPU 간 전송해야 함
- **결과**: 데이터 전송 오버헤드로 인한 심각한 성능 저하
- **해결책**: SET_ROWS Q4_0 지원 완료 후 KV 캐시를 GPU로 이동

### 2. 작은 배치 크기
- **현재**: n_batch=64, n_ubatch=8
- **영향**: GPU 활용률이 낮을 수 있음
- **권장**: 현재 설정이 최적 (128은 더 느렸음)

### 3. 프롬프트 평가 청크 크기
- **현재**: 64 토큰씩 처리
- **영향**: 각 청크 처리 시간이 길 수 있음
- **상태**: n_batch와 일치하여 최적화됨

### 4. OpenCL 백엔드 동기화 오버헤드
- **현재**: SET_ROWS Q4_0 연산 시 동기화 필요
- **영향**: GPU 커널 실행 후 동기화로 인한 지연
- **상태**: 크래시 방지를 위한 필수 조치

## 성능 개선 권장 사항

### 즉시 적용 가능한 최적화

1. **KV 캐시 GPU 할당 (최우선)**
   - SET_ROWS Q4_0 지원이 완료되었으므로 KV 캐시를 GPU로 이동
   - **예상 개선**: 5-10배 성능 향상
   - **작업**: `llama-kv-cache.cpp`와 `llama-context.cpp`에서 CPU 강제 할당 제거

2. **배치 크기 최적화 검증**
   - 현재 n_batch=64가 최적임을 확인
   - 추가 튜닝은 KV 캐시 GPU 이동 후 재평가

### 중장기 최적화

1. **OpenCL 커널 최적화**
   - SET_ROWS Q4_0 커널 성능 튜닝
   - 동기화 오버헤드 최소화

2. **동적 배치 크기 조정**
   - 프롬프트 길이에 따라 배치 크기 동적 조정
   - 짧은 프롬프트는 작은 배치, 긴 프롬프트는 큰 배치

3. **GPU 레이어 수 최적화**
   - 현재 31 레이어 (거의 모든 레이어)
   - VRAM 사용량과 성능 균형 재평가

## 현재 상태 요약

### 해결된 문제
- ✅ 크래시 해결: `ggml_backend_opencl_buffer_get_tensor`에서 타입 체크 추가
- ✅ 안정성 확보: 앱이 정상적으로 실행되고 토큰 생성 가능
- ✅ OpenCL 백엔드: 정상 작동 중
- ✅ SET_ROWS Q4_0 지원: 구현 완료

### 성능 이슈
- ⚠️ 프롬프트 평가: 매우 느림 (261 ms/token)
- ⚠️ KV 캐시 위치: CPU에 있어 GPU 연산 시 오버헤드 발생
- ⚠️ 처리량: 목표 대비 5-13배 느림

### 개선 필요 사항
- 🔧 KV 캐시 GPU 할당 (가장 중요)
- 🔧 OpenCL 백엔드 성능 튜닝
- 🔧 동적 배치 크기 최적화

## 다음 단계

1. **KV 캐시 GPU 할당 구현**
   - `llama-kv-cache.cpp`에서 CPU 강제 할당 제거
   - `llama-context.cpp`에서 CPU 강제 할당 제거
   - 성능 테스트 및 검증

2. **성능 재측정**
   - KV 캐시 GPU 이동 후 성능 재측정
   - 목표 성능 (20-50 ms/token) 달성 여부 확인

3. **추가 최적화**
   - 목표 성능 미달성 시 추가 최적화 진행
   - GPU 레이어 수, 배치 크기 등 추가 튜닝

## 결론

현재 프롬프트 평가 성능은 **목표 대비 5-13배 느린 상태**입니다. 가장 큰 병목은 **KV 캐시가 CPU에 할당**되어 GPU 연산 시 데이터 전송 오버헤드가 발생하는 것입니다.

SET_ROWS Q4_0 지원이 완료되었으므로, 이제 KV 캐시를 GPU로 이동하여 **5-10배의 성능 향상**을 기대할 수 있습니다. 이를 통해 목표 성능 (20-50 ms/token)에 근접할 수 있을 것으로 예상됩니다.

