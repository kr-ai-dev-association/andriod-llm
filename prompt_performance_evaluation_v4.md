# 프롬프트 평가 성능 분석 v4 (GPU 레이어 32)

## 측정 일시
- 2024-11-17 00:15:39 ~ 00:15:51

## 최신 성능 측정 결과

### 전체 프롬프트 평가
- **총 토큰 수:** 327 토큰
- **총 소요 시간:** 12,642 ms (약 12.6초)
- **평균 토큰당 시간:** **38.66 ms/token** ⭐
- **처리량:** **25.87 tokens/sec** ⭐

### 청크별 성능 분석

| 청크 | 토큰 범위 | 소요 시간 | 평균 ms/token | 비고 |
|------|----------|----------|---------------|------|
| 청크 1 | 0-128 | 4,217 ms | 32.95 | 첫 청크 (초기화 오버헤드) |
| 청크 2 | 128-256 | 4,617 ms | 36.07 | 중간 청크 |
| 청크 3 | 256-327 | 3,807 ms | 53.62 | 마지막 청크 (작은 크기) |

**관찰:**
- 첫 번째와 두 번째 청크가 매우 빠름 (32-36 ms/token) - 목표 범위 내!
- 마지막 청크(71 토큰)가 상대적으로 느림 (53.62 ms/token)
- 작은 청크 크기로 인한 GPU 활용률 저하

## 성능 개선 추이

| 버전 | 설정 | ms/token | tokens/sec | 개선율 |
|------|------|----------|------------|--------|
| 초기 | KV 캐시 CPU | 168.82 | 5.93 | 기준 |
| v2 | KV 캐시 GPU | 168.82 | 5.93 | 0% |
| v3 | 배치 128, 로그 제거 | 93.02 | 10.75 | +45% |
| **v4** | **GPU 레이어 32** | **38.66** | **25.87** | **+58% (v3 대비)** |

**총 개선율:** 초기 대비 **77% 개선** (168.82 → 38.66 ms/token)

## 목표 성능 대비

| 항목 | 목표 | 현재 | 달성률 | 상태 |
|------|------|------|--------|------|
| 프롬프트 평가 | 20-50 ms/token | 38.66 ms/token | **77.3%** | ✅ **목표 범위 내!** |
| 처리량 | 20-50 tokens/sec | 25.87 tokens/sec | **51.7-129.4%** | ✅ **목표 달성!** |

**결과:** 🎉 **목표 성능 달성!** (목표 범위: 20-50 ms/token)

## 현재 시스템 설정

```kotlin
nCtx = 512
nBatch = 128        // 최적화: 64 → 128
nUbatch = 16        // 최적화: 8 → 16
nGpuLayers = 32     // 최적화: 31 → 32 (모든 레이어 GPU 오프로드)
nThreads = 8
백엔드: OpenCL
KV 캐시: GPU (OpenCL)
청크 크기: 128 (n_batch와 일치)
```

## 적용된 최적화

1. ✅ **배치 크기 증가** (64 → 128)
   - GPU 활용률 향상
   - 데이터 전송 오버헤드 감소

2. ✅ **디버그 로그 제거**
   - `sync_with_other_backends` 로그 제거
   - `ggml_backend_opencl_graph_compute` 로그 제거
   - `ggml_backend_opencl_buffer_get_tensor` 로그 제거

3. ✅ **동적 청크 크기 최적화**
   - 청크 크기 = n_batch (128)
   - GPU 메모리 효율성 극대화

4. ✅ **KV 캐시 GPU 할당** (이전)
   - SET_ROWS Q4_0 지원 추가
   - CPU-GPU 데이터 전송 오버헤드 제거

5. ✅ **GPU 레이어 수 최대화** (31 → 32)
   - 모든 레이어를 GPU에 오프로드
   - CPU-GPU 전환 오버헤드 완전 제거
   - **가장 큰 성능 향상 요인**

## 성능 병목 지점 분석

### 1. 청크 처리 시간 분석
- **청크당 평균 시간:** 약 4-5초 (큰 청크), 3.8초 (작은 청크)
- **토큰당 평균 시간:** 32-36 ms/token (큰 청크), 53.62 ms/token (작은 청크)
- **관찰:** 마지막 작은 청크(71 토큰)가 상대적으로 느림

### 2. 잠재적 추가 최적화
- **작은 청크 병합:** 마지막 청크를 이전 청크와 병합하여 GPU 활용률 향상
- **OpenCL 커널 최적화:** SET_ROWS Q4_0 커널 워크그룹 크기 조정
- **메모리 접근 패턴 최적화:** 텐서 메모리 정렬 최적화

## 결론

### 🎉 목표 성능 달성!

**현재 성능:** 38.66 ms/token (목표 범위: 20-50 ms/token)
- ✅ **목표 범위 내 달성**
- ✅ 초기 대비 **77% 개선**
- ✅ v3 대비 **58% 추가 개선**

**주요 성과:**
1. GPU 레이어 수를 32로 증가시킨 것이 가장 큰 성능 향상 요인
2. 배치 크기 증가와 로그 제거도 상당한 기여
3. 목표 범위(20-50 ms/token) 내에서 안정적인 성능 달성

**추가 최적화 여지:**
- 작은 청크 병합으로 마지막 청크 성능 개선 가능
- OpenCL 커널 최적화로 추가 10-20% 개선 가능
- 하지만 현재 성능으로도 실용적인 수준 달성

