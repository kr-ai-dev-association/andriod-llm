# 프롬프트 평가 성능 향상 분석 보고서

## 1. 현재 상태 분석

### 1.1 현재 설정값
- **n_batch**: 512 (프롬프트 평가 배치 크기)
- **n_ubatch**: 2 (마이크로 배치 크기)
- **n_threads_batch**: n_threads와 동일 (배치 처리 스레드 수)
- **chunk_size**: n_batch와 동일 (512)
- **GPU Layers**: 29
- **KV Cache**: K-Cache Q4_0, V-Cache F16
- **Memory**: DEVICE_LOCAL (no_host=true)

### 1.2 현재 프롬프트 평가 프로세스
1. 프롬프트를 토큰화
2. n_batch 크기(512)로 청크 분할
3. 각 청크를 순차적으로 `llama_decode()` 호출
4. 모든 logits 비활성화 (Vulkan 백엔드 이슈 방지)
5. 마지막 토큰만 별도로 decode하여 logits 획득

### 1.3 성능 병목 지점
- **순차적 배치 처리**: 각 청크를 순차적으로 처리하여 GPU 활용률 저하
- **작은 마지크로 배치**: n_ubatch=2로 인한 GPU 병렬 처리 제한
- **배치 크기 제한**: n_batch=512가 최적값인지 불확실
- **메모리 전송 오버헤드**: 배치 초기화/해제 반복

## 2. JNI 레이어 최적화 방안

### 2.1 배치 크기 동적 조정 (우선순위: 높음)
**현재 문제점:**
- 고정된 n_batch=512 사용
- 프롬프트 길이에 따라 최적 배치 크기가 다를 수 있음

**개선 방안:**
```cpp
// 프롬프트 길이에 따라 동적 배치 크기 조정
uint32_t calculate_optimal_chunk_size(uint32_t n_tokens, uint32_t n_batch) {
    if (n_tokens <= 64) {
        return n_tokens;  // 작은 프롬프트는 전체를 한 번에 처리
    } else if (n_tokens <= 256) {
        return std::min(n_batch / 2, n_tokens);  // 중간 크기는 절반
    } else {
        return n_batch;  // 큰 프롬프트는 전체 배치 크기 사용
    }
}
```

**예상 효과:**
- 작은 프롬프트: 20-30% 성능 향상 (불필요한 배치 분할 제거)
- 중간 프롬프트: 10-15% 성능 향상

### 2.2 배치 재사용 (우선순위: 중간)
**현재 문제점:**
- 매 청크마다 `llama_batch_init()` / `llama_batch_free()` 호출
- 메모리 할당/해제 오버헤드

**개선 방안:**
```cpp
// 배치를 한 번만 초기화하고 재사용
llama_batch batch = llama_batch_init(n_batch, 0, 1);
for (int cur = 0; cur < n_tokens; ) {
    // 배치 크기만 조정하고 재사용
    batch.n_tokens = n_cur;
    // ... 토큰 채우기 ...
    llama_decode(ctx, batch);
    // 배치 해제하지 않고 재사용
}
llama_batch_free(batch);  // 마지막에 한 번만 해제
```

**예상 효과:**
- 메모리 할당 오버헤드 제거: 5-10% 성능 향상

### 2.3 병렬 배치 처리 (우선순위: 낮음, 복잡도 높음)
**현재 문제점:**
- 순차적 배치 처리로 GPU 유휴 시간 발생

**개선 방안:**
- 여러 배치를 파이프라인으로 처리
- **주의**: Vulkan 백엔드의 스레드 안전성 확인 필요

**예상 효과:**
- 이론적으로 2-3배 향상 가능하나, 구현 복잡도와 안정성 리스크 높음

## 3. GGML/Vulkan 백엔드 최적화 방안

### 3.1 n_ubatch 증가 (우선순위: 높음)
**현재 설정:**
```cpp
cparams.n_ubatch = 2;  // 매우 보수적인 값
```

**개선 방안:**
```cpp
// Adreno 830의 성능을 고려한 점진적 증가
cparams.n_ubatch = 4;  // 또는 8
```

**주의사항:**
- 메모리 사용량 증가
- 안정성 테스트 필수
- 점진적으로 증가하며 테스트

**예상 효과:**
- GPU 병렬 처리 향상: 15-25% 성능 향상 가능

### 3.2 Flash Attention 최적화 (우선순위: 중간)
**현재 설정:**
```cpp
cparams.flash_attn_type = LLAMA_FLASH_ATTN_TYPE_AUTO;
```

**개선 방안:**
- Vulkan 백엔드에서 Flash Attention 지원 여부 확인
- 지원되는 경우 명시적 활성화
- 지원되지 않는 경우 다른 attention 최적화 방법 탐색

**예상 효과:**
- Attention 연산 최적화: 10-20% 성능 향상 가능

### 3.3 KV Cache 최적화 (우선순위: 낮음)
**현재 설정:**
- K-Cache: Q4_0 (4-bit 양자화)
- V-Cache: F16 (16-bit float)

**개선 방안:**
- V-Cache도 Q4_0으로 변경 시도 (VRAM 절약, 성능 저하 가능)
- 현재 설정이 안정성과 성능의 균형점으로 보임

**주의사항:**
- 이전에 V-Cache Q4_0에서 Logit NaN 발생 이력 있음
- 변경 시 철저한 테스트 필요

### 3.4 GPU 레이어 수 최적화 (우선순위: 중간)
**현재 설정:**
```cpp
mparams.n_gpu_layers = 29;  // 전체 레이어 중 일부만 GPU 오프로드
```

**개선 방안:**
- 가능한 모든 레이어를 GPU로 오프로드
- CPU-GPU 전환 오버헤드 제거

**주의사항:**
- VRAM 부족 시 크래시 가능
- 점진적으로 증가하며 테스트

**예상 효과:**
- CPU-GPU 전환 오버헤드 제거: 5-15% 성능 향상

## 4. 메모리 및 캐시 최적화

### 4.1 배치 위치 계산 최적화 (우선순위: 중간)
**현재 코드:**
```cpp
free(batch.pos);
batch.pos = nullptr;  // llama_batch_allocr가 자동 계산
```

**개선 방안:**
- 위치를 미리 계산하여 재사용
- 반복 계산 오버헤드 제거

**예상 효과:**
- 위치 계산 오버헤드 제거: 2-5% 성능 향상

### 4.2 토큰 버퍼 사전 할당 (우선순위: 낮음)
**현재 코드:**
- 매번 토큰 배열을 동적 할당

**개선 방안:**
- 최대 프롬프트 길이에 맞춰 사전 할당
- 재할당 오버헤드 제거

**예상 효과:**
- 메모리 할당 오버헤드 제거: 1-3% 성능 향상

## 5. 구현 우선순위 및 권장사항

### 5.1 즉시 적용 가능 (낮은 리스크)
1. **배치 재사용** (2.2)
   - 구현 난이도: 낮음
   - 예상 효과: 5-10%
   - 리스크: 낮음

2. **동적 배치 크기 조정** (2.1)
   - 구현 난이도: 낮음
   - 예상 효과: 10-30% (프롬프트 크기에 따라)
   - 리스크: 낮음

### 5.2 신중한 테스트 필요 (중간 리스크)
3. **n_ubatch 증가** (3.1)
   - 구현 난이도: 낮음
   - 예상 효과: 15-25%
   - 리스크: 중간 (메모리 부족 가능)

4. **GPU 레이어 수 증가** (3.4)
   - 구현 난이도: 낮음
   - 예상 효과: 5-15%
   - 리스크: 중간 (VRAM 부족 가능)

### 5.3 장기 연구 필요 (높은 리스크)
5. **Flash Attention 최적화** (3.2)
   - 구현 난이도: 높음
   - 예상 효과: 10-20%
   - 리스크: 높음 (Vulkan 백엔드 지원 여부 불확실)

6. **병렬 배치 처리** (2.3)
   - 구현 난이도: 매우 높음
   - 예상 효과: 2-3배 (이론적)
   - 리스크: 매우 높음 (스레드 안전성 문제)

## 6. 예상 종합 효과

### 최적 시나리오 (낮은 리스크 최적화만 적용)
- 배치 재사용: +5-10%
- 동적 배치 크기: +10-30%
- **총 예상 향상: 15-40%**

### 최적 시나리오 (모든 최적화 적용)
- 위 최적화 + n_ubatch 증가: +15-25%
- GPU 레이어 증가: +5-15%
- **총 예상 향상: 35-80%**

## 7. 벤치마크 및 측정 방법

### 7.1 측정 지표
- 프롬프트 평가 시간 (토큰 수당)
- GPU 활용률
- 메모리 사용량
- 배치 처리 시간

### 7.2 테스트 케이스
1. 작은 프롬프트 (< 100 토큰)
2. 중간 프롬프트 (100-300 토큰)
3. 큰 프롬프트 (300-512 토큰)

## 8. 결론

**즉시 적용 권장:**
1. 배치 재사용 구현
2. 동적 배치 크기 조정

**단계적 적용 권장:**
3. n_ubatch를 2 → 4 → 8로 점진적 증가
4. GPU 레이어 수 증가 (29 → 33)

**장기 연구:**
5. Flash Attention 최적화
6. 병렬 배치 처리 (연구 단계)

이러한 최적화를 통해 **15-40%의 프롬프트 평가 성능 향상**을 기대할 수 있으며, 추가 최적화를 통해 **최대 80%까지 향상** 가능할 것으로 예상됩니다.

